{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPU can be seen\n",
    "# Will Fail on CPU ONLY, Should Pass on NVIDIA\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test bnlearn\n",
    "import bnlearn as bn\n",
    "df = bn.import_example()\n",
    "model = bn.structure_learning.fit(df)\n",
    "G = bn.plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pgmpy\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# 1. Define a simple network structure\n",
    "# A -> B -> C\n",
    "model = BayesianNetwork([('A', 'B'), ('B', 'C')])\n",
    "\n",
    "# 2. Define CPDs (Conditional Probability Distributions)\n",
    "cpd_a = TabularCPD(variable='A', variable_card=2, values=[[0.6], [0.4]])\n",
    "cpd_b = TabularCPD(variable='B', variable_card=2,\n",
    "                   values=[[0.7, 0.2],   # P(B=0|A)\n",
    "                           [0.3, 0.8]],  # P(B=1|A)\n",
    "                   evidence=['A'],\n",
    "                   evidence_card=[2])\n",
    "cpd_c = TabularCPD(variable='C', variable_card=2,\n",
    "                   values=[[0.9, 0.1],\n",
    "                           [0.1, 0.9]],\n",
    "                   evidence=['B'],\n",
    "                   evidence_card=[2])\n",
    "\n",
    "# 3. Add CPDs to the model\n",
    "model.add_cpds(cpd_a, cpd_b, cpd_c)\n",
    "\n",
    "# 4. Check if model is valid\n",
    "assert model.check_model(), \"Model is invalid!\"\n",
    "\n",
    "# 5. Perform inference\n",
    "infer = VariableElimination(model)\n",
    "result = infer.query(variables=['C'], evidence={'A': 1})\n",
    "print(\"P(C | A=1):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test GPyTorch\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Training data: simple noisy sine function\n",
    "train_x = torch.linspace(0, 1, 100, device=device)\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + 0.2 * torch.randn(train_x.size(), device=device)\n",
    "\n",
    "# Define a simple GP Model\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "model = ExactGPModel(train_x, train_y, likelihood).to(device)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 50\n",
    "for i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iter {i + 1}/{training_iter} - Loss: {loss.item():.3f}')\n",
    "    optimizer.step()\n",
    "\n",
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions\n",
    "test_x = torch.linspace(0, 1, 51, device=device)\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "# Plot results\n",
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "# Plot training data as black stars\n",
    "ax.plot(train_x.cpu().numpy(), train_y.cpu().numpy(), 'k*')\n",
    "# Plot predictive mean as blue line\n",
    "ax.plot(test_x.cpu().numpy(), observed_pred.mean.cpu().numpy(), 'b')\n",
    "# Shade confidence\n",
    "lower, upper = observed_pred.confidence_region()\n",
    "ax.fill_between(test_x.cpu().numpy(), lower.cpu().numpy(), upper.cpu().numpy(), alpha=0.5)\n",
    "ax.set_title(\"GPyTorch regression example\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
